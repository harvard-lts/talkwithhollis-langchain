PRIMO_API_HOST=host
PRIMO_API_KEY=key

# Configures whether book lists are compiled by the llm or via python code
# Via the llm was the initial method, but since it's just manipulating json, this is more efficient with python code currently
# This functionality is preserved for now and configured off in case we want the llm to do something more with the data in the future
LLM_DO_RESPONSE_FORMATTING=false

# openai or azure or amazon
AI_PLATFORM=amazon

# AWS credentials
# https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-envvars.html
AWS_ACCESS_KEY_ID=key
AWS_SECRET_ACCESS_KEY=key
AWS_DEFAULT_REGION=us-east-1
# Profile name for AWS credentials (required if using credentials file)
#AWS_BEDROCK_PROFILE_NAME=talkwithhollis
AWS_BEDROCK_MODEL_ID=anthropic.claude-instant-v1

PRIMO_API_HOST=host
PRIMO_API_KEY=key
PRIMO_API_LIMIT=100

# openai or azure or amazon
AI_PLATFORM=amazon

# Configures whether book lists are compiled by the llm or via python code
# Via the llm was the initial method, but since it's just manipulating json, this is more efficient with python code currently
# This functionality is preserved for now and configured off in case we want the llm to do something more with the data in the future
LLM_DO_RESPONSE_FORMATTING=false
MAX_RESULTS_TO_LLM=5

# AWS credentials
# https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-envvars.html
AWS_ACCESS_KEY_ID=key
AWS_SECRET_ACCESS_KEY=key
AWS_DEFAULT_REGION=us-east-1
# Profile name for AWS credentials (required if using credentials file)
#AWS_BEDROCK_PROFILE_NAME=example
AWS_BEDROCK_MODEL_ID=anthropic.claude-instant-v1

# If libcal library hours have not been refreshed in this many seconds, refresh them. Recommended 1 day. (1 day = 86400 seconds)
LIBCAL_REFRESH_TIME=86400
LIBCAL_CLIENT_ID=client_id
LIBCAL_CLIENT_SECRET=client_secret
LIBCAL_TOKEN_API_ROUTE=libcal_token_api_route
LIBCAL_HOURS_API_ROUTE=libcal_hours_api_route

HOLLIS_API_HOST=https://example.hollis.com/search
